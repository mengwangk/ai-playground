{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn_howto_2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "WsxyLwQgN-gw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898
        },
        "outputId": "11948343-b7b3-44c0-b191-41ac0ee2bc67"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision ipywidgets"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (7.4.2)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (4.6.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (3.4.2)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (4.3.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (4.4.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets) (4.5.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.2.4)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.4.0->ipywidgets) (5.2.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.3.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.1.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (40.7.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (1.0.15)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.6.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.4.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets) (2.6.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (17.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.5.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (5.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (2.10)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.6.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (3.1.0)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (0.5.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (1.4.2)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (0.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (1.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets) (0.5.1)\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.4.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2VPwJU1zN0PR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interact_manual\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib.pyplot import plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N0j8FgC9Ogpm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@interact\n",
        "def show_articles_more_than(column='claps', x=5000):\n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MMjvbgEiN0PX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# PyTorch Implementation"
      ]
    },
    {
      "metadata": {
        "id": "-svXpDwoPBrY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://medium.com/dair-ai/a-simple-neural-network-from-scratch-with-pytorch-and-google-colab-c7f3830618e0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4NF1j1cuN0PX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ILiUIF3N0Pc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = torch.tensor(([2, 9], [1, 5], [3, 6]), dtype=torch.float) # 3 X 2 tensor\n",
        "y = torch.tensor(([92], [100], [89]), dtype=torch.float) # 3 X 1 tensor\n",
        "xPredicted = torch.tensor(([4, 8]), dtype=torch.float) # 1 X 2 tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yGRW4PcYOyFJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4362cd19-b0b4-4794-fe60-69daa3a9e219"
      },
      "cell_type": "code",
      "source": [
        "print(X.size())\n",
        "print(y.size())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 2])\n",
            "torch.Size([3, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1O2lEI5sO8X4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "ee01d2a8-c486-4c5d-98e7-9691816d0e07"
      },
      "cell_type": "code",
      "source": [
        "# scale units\n",
        "X_max, _ = torch.max(X,0)\n",
        "xPredicted_max, _ = torch.max(xPredicted, 0)\n",
        "print(xPredicted_max)\n",
        "\n",
        "X = torch.div(X, X_max)\n",
        "xPredicted = torch.div(xPredicted, xPredicted_max)\n",
        "y = y / 100  # max test score is 100\n",
        "\n",
        "print(X)\n",
        "print(xPredicted)\n",
        "print(y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(8.)\n",
            "tensor([[0.6667, 1.0000],\n",
            "        [0.3333, 0.5556],\n",
            "        [1.0000, 0.6667]])\n",
            "tensor([0.5000, 1.0000])\n",
            "tensor([[0.9200],\n",
            "        [1.0000],\n",
            "        [0.8900]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dL-KfTZ9PRjh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Neural_Network(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        super(Neural_Network, self).__init__()\n",
        "        # parameters\n",
        "        # TODO: parameters can be parameterized instead of declaring them here\n",
        "        self.inputSize = 2\n",
        "        self.outputSize = 1\n",
        "        self.hiddenSize = 3\n",
        "        \n",
        "        # weights\n",
        "        self.W1 = torch.randn(self.inputSize, self.hiddenSize) # 3 X 2 tensor\n",
        "        self.W2 = torch.randn(self.hiddenSize, self.outputSize) # 3 X 1 tensor\n",
        "        \n",
        "    def forward(self, X):\n",
        "        self.z = torch.matmul(X, self.W1) # 3 X 3 \".dot\" does not broadcast in PyTorch\n",
        "        self.z2 = self.sigmoid(self.z) # activation function\n",
        "        self.z3 = torch.matmul(self.z2, self.W2)\n",
        "        o = self.sigmoid(self.z3) # final activation function\n",
        "        return o\n",
        "        \n",
        "    def sigmoid(self, s):\n",
        "        return 1 / (1 + torch.exp(-s))\n",
        "    \n",
        "    def sigmoidPrime(self, s):\n",
        "        # derivative of sigmoid\n",
        "        return s * (1 - s)\n",
        "    \n",
        "    def backward(self, X, y, o):\n",
        "        self.o_error = y - o # error in output\n",
        "        self.o_delta = self.o_error * self.sigmoidPrime(o) # derivative of sig to error\n",
        "        self.z2_error = torch.matmul(self.o_delta, torch.t(self.W2))\n",
        "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.z2)\n",
        "        self.W1 += torch.matmul(torch.t(X), self.z2_delta)\n",
        "        self.W2 += torch.matmul(torch.t(self.z2), self.o_delta)\n",
        "        \n",
        "    def train(self, X, y):\n",
        "        # forward + backward pass for training\n",
        "        o = self.forward(X)\n",
        "        self.backward(X, y, o)\n",
        "        \n",
        "    def saveWeights(self, model):\n",
        "        # we will use the PyTorch internal storage functions\n",
        "        torch.save(model, \"NN\")\n",
        "        # you can reload model with all the weights and so forth with:\n",
        "        # torch.load(\"NN\")\n",
        "        \n",
        "    def predict(self):\n",
        "        print (\"Predicted data based on trained weights: \")\n",
        "        print (\"Input (scaled): \\n\" + str(xPredicted))\n",
        "        print (\"Output: \\n\" + str(self.forward(xPredicted)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4S0gQTrvblxD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "5c5ed2cd-cf08-4309-c221-e31f41131bd1"
      },
      "cell_type": "code",
      "source": [
        "NN = Neural_Network()\n",
        "for i in range(10):  # trains the NN 1,000 times\n",
        "    print (\"#\" + str(i) + \" Loss: \" + str(torch.mean((y - NN(X))**2).detach().item()))  # mean sum squared loss\n",
        "    NN.train(X, y)\n",
        "NN.saveWeights(NN)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#0 Loss: 0.38415220379829407\n",
            "#1 Loss: 0.29589390754699707\n",
            "#2 Loss: 0.2200423628091812\n",
            "#3 Loss: 0.1615748554468155\n",
            "#4 Loss: 0.119322270154953\n",
            "#5 Loss: 0.08957938104867935\n",
            "#6 Loss: 0.06868519634008408\n",
            "#7 Loss: 0.053844403475522995\n",
            "#8 Loss: 0.043120235204696655\n",
            "#9 Loss: 0.03521812707185745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type Neural_Network. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "OqRsveM-dvGz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# NumPy Implementation"
      ]
    },
    {
      "metadata": {
        "id": "6bPw0aIoejkC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# X = (hours sleeping, hours studying), y = score on test\n",
        "X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n",
        "y = np.array(([92], [86], [89]), dtype=float)\n",
        "\n",
        "# scale units\n",
        "X = X/np.amax(X, axis=0) # maximum of X array\n",
        "y = y/100 # max test score is 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7tXgXFyDgLpb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3162
        },
        "outputId": "b20c3df1-0291-4725-baaf-065d769802e4"
      },
      "cell_type": "code",
      "source": [
        "class Neural_Network(object):\n",
        "  def __init__(self):\n",
        "    #parameters\n",
        "    self.inputSize = 2\n",
        "    self.outputSize = 1\n",
        "    self.hiddenSize = 3\n",
        "\n",
        "    #weights\n",
        "    self.W1 = np.random.randn(self.inputSize, self.hiddenSize) # (3x2) weight matrix from input to hidden layer\n",
        "    self.W2 = np.random.randn(self.hiddenSize, self.outputSize) # (3x1) weight matrix from hidden to output layer\n",
        "\n",
        "  def forward(self, X):\n",
        "    #forward propagation through our network\n",
        "    self.z = np.dot(X, self.W1) # dot product of X (input) and first set of 3x2 weights\n",
        "    self.z2 = self.sigmoid(self.z) # activation function\n",
        "    self.z3 = np.dot(self.z2, self.W2) # dot product of hidden layer (z2) and second set of 3x1 weights\n",
        "    o = self.sigmoid(self.z3) # final activation function\n",
        "    return o\n",
        "\n",
        "  def sigmoid(self, s):\n",
        "    # activation function\n",
        "    return 1/(1+np.exp(-s))\n",
        "\n",
        "  def sigmoidPrime(self, s):\n",
        "    #derivative of sigmoid\n",
        "    return s * (1 - s)\n",
        "\n",
        "  def backward(self, X, y, o):\n",
        "    # backward propagate through the network\n",
        "    self.o_error = y - o # error in output\n",
        "    self.o_delta = self.o_error*self.sigmoidPrime(o) # applying derivative of sigmoid to error\n",
        "\n",
        "    self.z2_error = self.o_delta.dot(self.W2.T) # z2 error: how much our hidden layer weights contributed to output error\n",
        "    self.z2_delta = self.z2_error*self.sigmoidPrime(self.z2) # applying derivative of sigmoid to z2 error\n",
        "\n",
        "    self.W1 += X.T.dot(self.z2_delta) # adjusting first set (input --> hidden) weights\n",
        "    self.W2 += self.z2.T.dot(self.o_delta) # adjusting second set (hidden --> output) weights\n",
        "\n",
        "  def train(self, X, y):\n",
        "    o = self.forward(X)\n",
        "    self.backward(X, y, o)\n",
        "\n",
        "  def saveWeights(self):\n",
        "    np.savetxt(\"w1.txt\", self.W1, fmt=\"%s\")\n",
        "    np.savetxt(\"w2.txt\", self.W2, fmt=\"%s\")\n",
        "\n",
        "  def predict(self):\n",
        "    print(\"Predicted data based on trained weights: \")\n",
        "    print(\"Input (scaled): \\n\" + str(xPredicted))\n",
        "    print(\"Output: \\n\" + str(self.forward(xPredicted)))\n",
        " \n",
        "\n",
        "NN = Neural_Network()\n",
        "for i in range(10): # trains the NN 1,000 times\n",
        "  print(\"# \" + str(i) + \"\\n\")\n",
        "  print(\"Input (scaled): \\n\" + str(X))\n",
        "  print(\"Actual Output: \\n\" + str(y))\n",
        "  print(\"Predicted Output: \\n\" + str(NN.forward(X)))\n",
        "  print(\"Loss: \\n\" + str(np.mean(np.square(y - NN.forward(X))))) # mean sum squared loss\n",
        "  print(\"\\n\")\n",
        "  NN.train(X, y)\n",
        "\n",
        "NN.saveWeights()\n",
        "NN.predict()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# 0\n",
            "\n",
            "Input (scaled): \n",
            "[[0.66666667 1.        ]\n",
            " [0.33333333 0.55555556]\n",
            " [1.         0.66666667]]\n",
            "Actual Output: \n",
            "[[0.92]\n",
            " [0.86]\n",
            " [0.89]]\n",
            "Predicted Output: \n",
            "[[0.05063151]\n",
            " [0.06149561]\n",
            " [0.0710382 ]]\n",
            "Loss: \n",
            "0.6880364199717403\n",
            "\n",
            "\n",
            "# 1\n",
            "\n",
            "Input (scaled): \n",
            "[[0.66666667 1.        ]\n",
            " [0.33333333 0.55555556]\n",
            " [1.         0.66666667]]\n",
            "Actual Output: \n",
            "[[0.92]\n",
            " [0.86]\n",
            " [0.89]]\n",
            "Predicted Output: \n",
            "[[0.06059372]\n",
            " [0.07161425]\n",
            " [0.08420886]]\n",
            "Loss: \n",
            "0.6698102027485854\n",
            "\n",
            "\n",
            "# 2\n",
            "\n",
            "Input (scaled): \n",
            "[[0.66666667 1.        ]\n",
            " [0.33333333 0.55555556]\n",
            " [1.         0.66666667]]\n",
            "Actual Output: \n",
            "[[0.92]\n",
            " [0.86]\n",
            " [0.89]]\n",
            "Predicted Output: \n",
            "[[0.07364416]\n",
            " [0.08456361]\n",
            " [0.10104928]]\n",
            "Loss: \n",
            "0.6466876820067079\n",
            "\n",
            "\n",
            "# 3\n",
            "\n",
            "Input (scaled): \n",
            "[[0.66666667 1.        ]\n",
            " [0.33333333 0.55555556]\n",
            " [1.         0.66666667]]\n",
            "Actual Output: \n",
            "[[0.92]\n",
            " [0.86]\n",
            " [0.89]]\n",
            "Predicted Output: \n",
            "[[0.09088985]\n",
            " [0.10129148]\n",
            " [0.12261858]]\n",
            "Loss: \n",
            "0.6173121695832281\n",
            "\n",
            "\n",
            "# 4\n",
            "\n",
            "Input (scaled): \n",
            "[[0.66666667 1.        ]\n",
            " [0.33333333 0.55555556]\n",
            " [1.         0.66666667]]\n",
            "Actual Output: \n",
            "[[0.92]\n",
            " [0.86]\n",
            " [0.89]]\n",
            "Predicted Output: \n",
            "[[0.11370333]\n",
            " [0.12297353]\n",
            " [0.15003564]]\n",
            "Loss: \n",
            "0.5802898625560949\n",
            "\n",
            "\n",
            "# 5\n",
            "\n",
            "Input (scaled): \n",
            "[[0.66666667 1.        ]\n",
            " [0.33333333 0.55555556]\n",
            " [1.         0.66666667]]\n",
            "Actual Output: \n",
            "[[0.92]\n",
            " [0.86]\n",
            " [0.89]]\n",
            "Predicted Output: \n",
            "[[0.14352983]\n",
            " [0.1508864 ]\n",
            " [0.18414259]]\n",
            "Loss: \n",
            "0.5346609002518533\n",
            "\n",
            "\n",
            "# 6\n",
            "\n",
            "Input (scaled): \n",
            "[[0.66666667 1.        ]\n",
            " [0.33333333 0.55555556]\n",
            " [1.         0.66666667]]\n",
            "Actual Output: \n",
            "[[0.92]\n",
            " [0.86]\n",
            " [0.89]]\n",
            "Predicted Output: \n",
            "[[0.18136632]\n",
            " [0.1860458 ]\n",
            " [0.2249196 ]]\n",
            "Loss: \n",
            "0.4807086364003547\n",
            "\n",
            "\n",
            "# 7\n",
            "\n",
            "Input (scaled): \n",
            "[[0.66666667 1.        ]\n",
            " [0.33333333 0.55555556]\n",
            " [1.         0.66666667]]\n",
            "Actual Output: \n",
            "[[0.92]\n",
            " [0.86]\n",
            " [0.89]]\n",
            "Predicted Output: \n",
            "[[0.22693714]\n",
            " [0.22859061]\n",
            " [0.27089727]]\n",
            "Loss: \n",
            "0.42076738142372533\n",
            "\n",
            "\n",
            "# 8\n",
            "\n",
            "Input (scaled): \n",
            "[[0.66666667 1.        ]\n",
            " [0.33333333 0.55555556]\n",
            " [1.         0.66666667]]\n",
            "Actual Output: \n",
            "[[0.92]\n",
            " [0.86]\n",
            " [0.89]]\n",
            "Predicted Output: \n",
            "[[0.27810428]\n",
            " [0.27722048]\n",
            " [0.31918248]]\n",
            "Loss: \n",
            "0.3591649098024145\n",
            "\n",
            "\n",
            "# 9\n",
            "\n",
            "Input (scaled): \n",
            "[[0.66666667 1.        ]\n",
            " [0.33333333 0.55555556]\n",
            " [1.         0.66666667]]\n",
            "Actual Output: \n",
            "[[0.92]\n",
            " [0.86]\n",
            " [0.89]]\n",
            "Predicted Output: \n",
            "[[0.3313437 ]\n",
            " [0.32928618]\n",
            " [0.36647248]]\n",
            "Loss: \n",
            "0.30075149111279936\n",
            "\n",
            "\n",
            "Predicted data based on trained weights: \n",
            "Input (scaled): \n",
            "tensor([0.5000, 1.0000])\n",
            "Output: \n",
            "[0.37575231]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XBenY0I4itGB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}